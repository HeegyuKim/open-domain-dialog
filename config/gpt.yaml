
project: open-domain-dialog
run_name: kodialogpt-base-v1

logger: 
  name: wandb
  val_sample_batches: 10
  val_sample_generation_params:
    max_new_tokens: 32
    eos_token_id: 375 # \n
    max_prompt_length: 224
    num_beams: 4
    no_repeat_ngram_size: 4
    repetition_penalty: 2.0
    do_sample: true
    top_k: 50

dataset:
  train:
    shuffle: false
    streaming: true
    use_auth_token: true
    paths:
      - heegyu/aihub_daily_conv_2022_gpt
      - heegyu/nikl_online_conv_2022_gpt
      - heegyu/aihub_sns_dialog_gpt
      - heegyu/aihub_twitter_dialog_gpt
      - heegyu/aihub_emotional_dialog_gpt
    weights: [87690, 74665, 1599992, 2000, 10000]
  validation:
    use_auth_token: true
    split: test
    paths:
      - heegyu/aihub_daily_conv_2022_CRF

optimizer:
  cls: adamw
  learning_rate: 5e-5
  
trainer:
  train_epochs: 1
  train_batch_size: 4
  limit_val_batches: 10

  eval_batch_size: 4
  num_sanity_val_steps: 1
  val_check_interval: 10000
  # check_val_every_n_epoch: 1

model:
  plm: skt/kogpt2-base-v2
  max_seq_len: 512

tokenizer:
  add_special_tokens:
    pad_token: <pad>
    bos_token: <s>
    eos_token: </s>
    sep_token: '
    
    '